
<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
  <title>Priya Goyal</title>
  <meta name="description" content="Academic Website">
  <meta name="author" content="Priya Goyal">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="./css" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="./normalize.css">
  <link rel="stylesheet" href="./skeleton.css">
  <link rel="stylesheet" href="./custom.css">
  <link rel="stylesheet" href="./social-circles.min.css">


  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="SHORTCUT ICON" href="regularbicycle_sport_5056.ico"/>
  <link rel="apple-touch-icon" href="favicon_apple.ico"/>

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

 <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href="#about">ABOUT</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#media">TALKS / MEDIA COVERAGE</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#pubs">PUBLICATIONS</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#resume">RESUME</a></li>
        </ul>
      </div>
    </nav>


  <div class="container">
    <div class="row">
      <div class="one-half column" style="margin-top: 8.0%">
        <img class="bio-image" src="./images/priya-goyal.png" alt="">
      </div>
      <div class="one-half column" style="margin-top: 8.0%">
	    <br>
        <h2>Priya Goyal</h2>
        <p>Staff AI Research Engineer, <a href="https://deepmind.google/">Google Deepmind</a><br>
        <a class="project-link" href="https://scholar.google.com/citations?hl=en&user=-9yiQMsAAAAJ" target="_blank">Google Scholar</a> <br>
		<a class="project-link" href="https://www.linkedin.com/in/priyagoyal" target="_blank">LinkedIn</a> <br> <!-- &nbsp/&nbsp  -->
		<a href="https://twitter.com/priy2201">Twitter</a> <br>
		<a href="mailto:priy2201@gmail.com">Email</a> <br>
		<a href="https://github.com/prigoyal">Github</a> <br>
      </div>
    </div>

    <div class="row" style="margin-top: 5.5%" id="about">
      <p> I am a Founding Member of <a href="https://www.datologyai.com/">DatologyAI.</a></p>
      <p> Previously, I was a Staff AI Researcher at <a href="https://deepmind.google/">Google Deepmind</a> where I work on building fundamental Multimodal technology aimed at enabling new capabilities with LLMs. Before that, I spent almost 7 wonderful years at <a href="https://ai.facebook.com/">Facebook AI Research (FAIR)</a> in New York, USA where I worked on computer vision and machine learning. </p>

      <p>At FAIR, I led research on representation learning using <a href="https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision/">self-supervision from uncurated datasets</a>, training large-scale computer vision models (notable projects: <a href=https://arxiv.org/pdf/1706.02677.pdf>ImageNet in 1 Hour</a> and <a href="https://ai.facebook.com/blog/seer-10b-better-fairer-computer-vision-through-self-supervised-learning-training-on-diverse-datasets/">SEER 10 billion parameters self-supervised model</a>) and building <a href="https://ai.facebook.com/blog/meta-ai-research-explores-new-public-fairness-benchmarks-for-computer-vision-models/">socially responsible AI models</a>. I led the development of self-supervised learning library <a href=https://github.com/facebookresearch/vissl>VISSL</a> and am a recipient of the <a href="https://www.thecvf.com/?page_id=413#ICCVBestStudent">Best Student Paper Award</a> for <a href="https://arxiv.org/abs/1708.02002v2"> Focal Loss</a> at ICCV 2017. I also led and organized the <a href="https://sites.google.com/corp/view/fb-ssl-challenge-iccv19/home">first ever self-supervised learning challenge at ICCV'19</a>.</p>

<!--       <p>My research works have been covered in media including </p> -->
	    
      <p>My research interests include language modeling, evaluations for language models, instruction tuning, multimodal learning, computer vision, retrieval augmentation, personalized AI and developing socially responsible AI.</p>
    </div>
  </div>

<div class="container">

    <div class="row" style="margin-top: 2%" id="media">
      <h5>Talks / Media coverage</h5>
	    <p>
		    <a href="https://techcrunch.com/2017/06/08/facebook-is-speeding-up-training-for-visual-recognition-models/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAG4Or0N7KVlLFYEXlmemr1KrPSUgevom3nYWbtoIkxuZiWopa293ezKRdeogBMiaQSDlEhRg_CejOAs9sRv8T0QoxZh-e5uhrvt10XGRjg-WBGNnXnYxfhU7E70CPTeE1iQnz-VGKvjWfBi7vTIw8qg7KnCgfwHhP2lmy2HCVwvj">TechCrunch article on ImageNet in 1-Hour.</a><br>
		    <a href="https://www.cnbc.com/2021/03/04/facebook-trains-ai-to-see-using-1-billion-public-instagram-photos-.html">CNBC article on SEER (training A.I. to "see").</a><br>
		    <a href="https://developer.nvidia.com/blog/facebook-trains-imagenet-in-1-hour/">NVIDIA Developer on ImageNet on 1-Hour.</a><br>
		    <a href="https://www.geekwire.com/2017/facebooks-ai-training-models-can-now-process-40000-images-second/">Geekwire on ImageNet in 1-Hour.</a><br>
		    <a href="https://developer.nvidia.com/blog/facebook-self-supervised-ai/">NVIDIA Developer on Self-supervised learning beating SOTA Computer vision models.</a><br>
		    <a href="https://www.wired.com/story/facebook-new-ai-teaches-itself-see-less-human-help/">WIRED article on AI Teaching Itself to See With Less Human Help.</a><br>
		    <a href="https://www.cnet.com/science/facebook-trains-computers-to-learn-more-like-humans-do/">CNET on training computers to learn like humans do.</a><br>
		    <a href="https://supercomputersfordl2017.github.io/">ImageNet in 1-Hour at NeurIPS 2017 Supercomputing workshop.</a><br>
	    </p>
	    
    </div>
</div>

 <div class="container">

    <div class="row" style="margin-top: 2%" id="pubs">
      <h5>Publications</h5>
	    
    </div>
	
	<div class="row">
        <div class="five columns" style="margin-top: 2%">
        	<video  width=100% height=100% muted autoplay loop>
                <source src="images/CD21_855_SEER_Visual06.mp4" type="video/mp4">
                Your browser does not support the video tag.
             </video>
		    <!-- <img class="paper-image" src="images/CD21_855_SEER_Visual03b.jpeg" alt=""> -->
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision</b><br>
			  <em>arXiv</em>, 2022 <br>
			  <em> <u>Priya Goyal</u>, Quentin Duval, Isaac Seessel, Mathilde Caron, Ishan Misra, Levent Sagun, Armand Joulin, Piotr Bojanowski </em><br/>
			  <a href=https://arxiv.org/abs/2202.08360>[arXiv]</a> 
			  <a href=https://ai.facebook.com/blog/seer-10b-better-fairer-computer-vision-through-self-supervised-learning-training-on-diverse-datasets>[blogpost]</a> 
			  <a href=https://github.com/facebookresearch/vissl/blob/main/projects/SEER/README.md>[code]</a> 
			  <a href=projects/seer_10b_bib.txt>[bib]</a> 
			  <br/>
			</p>
		</div>
    </div>
	 
	<div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/CD21_855_SEER_Visual10.jpeg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Fairness Indicators for Systematic Assessments of Visual Feature Extractors</b><br>
			  <em>FAccT</em>, 2022 <br/>
			  <em> <u>Priya Goyal</u>, Adriana Romero Soriano, Caner Hazirbas, Levent Sagun, Nicolas Usunier </em><br/>
			  <a href=https://arxiv.org/abs/2202.07603>[arXiv]</a> 
			  <a href=https://ai.facebook.com/blog/meta-ai-research-explores-new-public-fairness-benchmarks-for-computer-vision-models>[blogpost]</a> 
			  <a href=https://github.com/facebookresearch/vissl/blob/main/projects/fairness_indicators/README.md>[code]</a> 
			  <a href=projects/fairness_bib.txt>[bib]</a> 
			  <br/> 
			</p>
		</div>
    </div>
	
	<div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <center><img align="middle" src="images/sscd_img2.png" alt="" width="150" height="120"><img align="middle" src="images/sscd.png" alt="" width="150" height="70"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>A Self-Supervised Descriptor for Image Copy Detection</b><br>
			  <em>arXiv</em>, 2022 <br/>
			  <em> Ed Pizzi, Sreya Dutta Roy, Sugosh Nagavara Ravindra, <u>Priya Goyal</u>, Matthijs Douze </em><br/>
			  <a href=https://arxiv.org/abs/2202.10261>[arXiv]</a> 
			  <a href=projects/sscd_bib.txt>[bib]</a> 
			  <br/> 
			</p>
		</div>
    </div>

    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <center><img align="middle" src="images/fsdp.png" alt="" width="250" height="150"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Fully Sharded Data Parallel: faster AI training with fewer GPUs</b><br>
			  <em>Facebook Engineering blog</em>, 2021 <br/>
			  <em> Myle Ott, Sam Shleifer, Min Xu, <u>Priya Goyal</u>, Quentin Duval, Vittorio Caggiano </em><br/>
			  <a href=https://engineering.fb.com/2021/07/15/open-source/fsdp/>[blog]</a> 
			  <a href=https://fairscale.readthedocs.io/en/stable/api/nn/fsdp.html>[docs]</a> 
			  <br/> 
			</p>
		</div>
    </div>
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
			<center><img align="middle" src="images/seer_low_shot.png" alt="" width="150" height="150"><img align="middle" src="images/seer_in1k_pull_figure.png" alt="" width="150" height="150"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Self-supervised pretraining of visual features in the wild</b><br>
			  <em>arXiv</em>, 2021 <br/>
			  <em><u>Priya Goyal</u>, Mathilde Caron, Benjamin Lefaudeux, Min Xu, Pengchao Wang, Vivek Pai, Mannat Singh, Vitaliy Liptchinsky, Ishan Misra, Armand Joulin, Piotr Bojanowski</em><br/>
			  <a href="https://arxiv.org/pdf/2103.01988.pdf">[arXiv]</a>
			  <a href=https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision/>[blogpost]</a> 
			  <a href="https://github.com/facebookresearch/vissl">[code]</a>
			  <a href=projects/seer_2021_bib.txt>[bib]</a> 
			  <br/>
			  
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/vissl_logo.png" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>VISSL: A library for state-of-the-art self-supervised learning from images</b><br>
			  <em>Released Jan'2021</em> <br/>
			  <em><u>Priya Goyal</u>, Quentin Duval, Jeremy Reizenstein, Matthew Leavitt, Min Xu, Benjamin Lefaudeux, Mannat Singh, Vinicius Reis, Mathilde Caron, Piotr Bojanowski, Armand Joulin, Ishan Misra</em><br/>
			  <a href="https://vissl.ai/">[website]</a>
			  <a href=https://vissl.ai/tutorials/>[tutorials]</a> 
			  <a href="https://github.com/facebookresearch/vissl">[Github]</a>
			  <a href="https://vissl.readthedocs.io/en/main/">[Docs]</a>
			  <a href=projects/vissl_bib.txt>[bib]</a>
			</p>
		</div>
    </div>	
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <center><img align="middle" src="images/swav.png" alt="" width="250" height="130"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</b><br>
			  <em>NeurIPS 2020</em><br/>
			  <em>Mathilde Caron, Ishan Misra, Julien Mairal, <u>Priya Goyal</u>, Piotr Bojanowski, Armand Joulin</em><br/>
			  <a href="https://arxiv.org/abs/2006.09882">[arXiv]</a>
			  <a href="https://ai.facebook.com/blog/high-performance-self-supervised-image-classification-with-contrastive-clustering/">[blogpost]</a>
			  <a href="https://github.com/facebookresearch/swav">[code]</a>
		      <a href="projects/swav_bib.txt">[bib]</a>
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <center><img align="middle" src="images/ssl_iccv19_v2.png" alt="" width="240" height="140"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Scaling and Benchmarking Self-Supervised Visual Representation Learning</b><br>
			  <em>ICCV 2019</em><br/>
			  <em><u>Priya Goyal</u>, Dhruv Mahajan, Abhinav Gupta*, Ishan Misra*</em><br/>
			  <a href="https://arxiv.org/abs/1905.01235">[arXiv]</a>
		      <a href="https://github.com/facebookresearch/fair_self_supervision_benchmark">[code]</a>
		      <a href="projects/ssl_iccv19_bib.txt">[bib]</a>
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <!-- <img class="paper-image" src="images/focal_loss.png" alt=""> -->
		    <center><img align="middle" src="images/focal_loss.png" alt="" width="200" height="100"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Focal Loss for Dense Object Detection</b><br>
			  <em>ICCV 2017</em> <font color="red"><strong> (best student paper award)</strong></font><br/>
			  <em>Tsung-Yi Lin, <u>Priya Goyal</u>, Ross Girshick, Kaiming He, Piotr Dollár</em><br/>
			  <a href="https://arxiv.org/abs/1708.02002v2">[arXiv]</a>
			  <a href="projects/focal_loss_bib.txt">[bib]</a>
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <!-- <img class="paper-image" src="images/uncertainty.jpg" alt=""> -->
		    <center><img align="middle" src="images/in1hr_fig1.png" alt="" width="150" height="150"><img align="middle" src="images/in1hr_fig2.png" alt="" width="150" height="150"></center>
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</b><br>
			  <em>arXiv 2017</em><br/>
			  <em><u>Priya Goyal</u>, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, Kaiming He</em><br/>
			  <a href="https://arxiv.org/abs/1706.02677">[arXiv]</a>
			  <a href="https://supercomputersfordl2017.github.io/">[NeurIPS 2017 talk]</a>
			  <br/>
			  
			</p>
		</div>
    </div>	
	
    
	
	
  <div class="container">

    <div class="row" style="margin-top: 2%" id="resume">
      <h4>Resume</h4>
    </div>
	
	<div class="row">
	    <p style="margin-bottom: 0rem">
	        <a href="resume/priya-goyal-resume-2023.pdf" style="text-decoration: none"><img  src="images/pfd.gif" height="30" alt=""/></a><a href="https://github.com/prigoyal/prigoyal.github.io/blob/master/resume/priya-goyal-resume-2023.pdf">PDF</a> 
	        <br />
	    </p>
	    <div class="twelve columns" style="margin-top: 2%">
		    <!--Used https://www.zamzar.com/convert/pdf-to-svg/ to convert pdf to svg-->
		    <img class="paper-image" src="resume/priya-goyal-resume-2023-pg1.svg" style="Border: 1px solid black;" alt="">
			<img class="paper-image" src="resume/Priya-Goyal-Resume-2023-pg2.svg" style="Border: 1px solid black;" alt="">
			<img class="paper-image" src="resume/Priya-Goyal-Resume-2023-pg3.svg" style="Border: 1px solid black;" alt="">
	    </div>
		<br/>
	</div>
	
  </div>	

<br>
<br>
<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->


</body></html>
